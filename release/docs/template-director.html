<h1>Managing large projects</h1>

<p>Syberia comes bundled with <a href="https://github.com/syberia/director">director</a>, an R6
package aimed at simplifying management of large R projects.</p>

<p>By default, most R projects are collections of loosely organized scripts. A
newcomer to the project would have to rely on very thorough documentation to understand
how the executable tasks fit together and how to replicate and expand on any analysis.</p>

<p>In Syberia, we rely on <a href="">convention over configuration</a>, a common design
pattern in software frameworks that removes some leeway in the organizational structure
in exchange for something incredibly powerful: all R developers working in Syberia projects
will share common knowledge about how work is organized.</p>

<p>In particular, the <a href="">modeling engine</a> that currently comes bundled as
the default engine for structured supervised learning projects such as regression and
classification sets up a few conventions which all modeling engine projects conform to:</p>

<p><ul>
  <li>The <b>models</b> directory holds all models for a given project. Each file is
  an R script that ends with a <code>list</code> object which hyper-parameterizes the
  data science process into a linear sequence of stages. All the conventions below are
  the recipe ingredients that turn model files from static lists to living, breathing
  objects defining a dynamic modeling pipeline.</li>
  <li>The <b>lib/adapters</b> directory defines IO (input and output) mechanisms for data
  and serialized model objects. For example, data might be read in CSV format, from a
  database or data warehouse, or simply reside in-memory. Data and model objects may
  be written to a file, to a cloud storage service, or pushed via HTTP to an API.</li>
  <li>The <b>lib/mungebits</b> directory defines mungebits, already familiar from an
  earlier lesson, which define feature engineering templates that transform dataframes
  to dataframes.</li>
  <li>The <b>lib/stages</b> directory is a collection of modeling stages, by default
  <i>import</i>, <i>data</i>, <i>model</i>, and <i>export</i>. The complex logic that
  defines how to process the parameters in the modeling file lives in these stages: 
  each R file in this directory is a functional, a function that returns another function,
  namely, a function that takes in the parameters from the model file and spits out a
  transformation of an environment that performs the appropriate operations of the stage.</li>
  <li>The <b>lib/classifiers</b> directory is responsible for housing all the training and
  prediction functions for various statistical classifiers: linear regression, random forest,
  gradient boosting machines, support vector machines, et cetera. These are responsible for
  the construction of a <i> model object</i>, a serializable R object that represents all
  meta-data required to replicate the scoring of outputs on new validation sets or real-time
  data.</li>
</ul></p>

<p>The following conventions are established by the <a href="">base engine</a>, which is
more general than the modeling engine and serves as the clay for almost all future Syberia
engines. For example, unsupervised learning, natural language processing, scientific research,
dashboarding and business intelligence, trading and finance, may all require different
conventions which differ somewhat or drastically from the structured supervised learning
problem. Building on top of the base engine allows for some very powerful meta-conventions:</p>

<p><ul>
  <li>The <b>config/routes</b> resource (typically just a routes.R file) established the
  link between the <b>lib/controllers</b> directory and the rest of the project: it tethers
  together which directories are processed by which controllers.</li>
  <li><p>The <b>lib/controllers</b> directory forms the heart of Syberia's expansive
  configurability. In an effort to strike the balance between establishing conventions
  over configurations, whilst suitably recognizing that the taxonomy of
  <a href="">computing tasks</a> may require different conventions to optimally iterate
  on its given set of problems, the notion of a <i>controller</i> allows us to
  <i>generalize how R works</i>. In the old way, we would use <code>base::source</code>
  to execute an R file and store the value of its last expression in a local variable.</p>
  <p>Controllers allow us to define <i>preprocessors</i> and <i>parsers</i>. A preprocessor
  is a function that specifies everything <i>before</i> we execute an R file and a parser
  is a function that specifies everything <i>after</i> we execute an R file--in a 
  given directory. In effect, controllers allow us to establish heterogeneous DSLs
  (domain-specific languages) in a hierarchical directory structure in a way that
  most optimally conforms to how we wish to solve a particular problem, whether it be
  production-ready machine learning or experimental business intelligence dashboarding.</p>
  <p>The Syberia team looks forward to the creativity and imagination the R community
  will display when fully unlocking the power of controllers: let the domain-specific
  languages flood out the rigidity of CRAN and the constraints of packages, thus
  establishing R as a true player in the "general purpose programming language" 
  sector. It is, after all, just a LISP--a rather powerful one at that.</li>
</ul></p>
  

