<html>

  <head>
    <script src="https://use.typekit.net/xdj4hmw.js"></script>
    <script type="text/javascript">try { Typekit.load({ async: true }); } catch(e) { }</script>

    <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,500" rel="stylesheet" type="text/css">
    <link rel="stylesheet" media="all" href="../style.css" type="text/css" />
    <link rel="stylesheet" media="all" href="../stylesheets/rocco.css" />
    <link rel="stylesheet" media="all" href="../stylesheets/github-markdown.css" />

    <script src="../assets/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>
  </head>

  <body>
  <div class="backdrop tk-proxima-nova">
    <div class="header">
      <div class="header-left">Syberia</div>
      <div class="header-right">
        <ul>
          <li><a href="#">Get Started</a></li>
          <li><a href="#">Docs</a></li>
        </ul>
      </div>
    </div>
    <br /> <br /> <br />
  </div>
  <div class="colmask leftmenu tk-proxima-nova">
    <div class="colleft">
      <div class="col1">
<h1>Stagerunner</h1>

<p>Experimenting with a data science task is usually done through
the R console or an IDE by executing portions of a file
or collection of files. Sometimes this is slightly generalized
into notebooks, interactive sessions that record the
history of the code you executed and its outputs, 
including plots, data, and summaries.</p>

<p>This kind of workflow works well in the old way, when
you don't intend on returning to your analysis for any
future use and are happy with a static image result.</p>

<p>Developers working on pure software engineering projects
usually operate in a different way: they manipulate a single
codebase and provide iterability and experimentability through
some other approach that ultimately ends up reflecting what's
in their codebase.</p>

<p>For example, a front-end web developer might change a
JavaScript file in the deep innards of a web app, hit refresh
on their browser, and test out the new functionality by clicking
their mouse.</p>

<p>To achieve a better data science workflow we will mirror
the effectiveness of the typical developer approach. 
We will rely on a <i>shared codebase</i> composed of
modular and testable resources that allows us to go back
in time using version control and have new components
vetted using code review.</p>

<p>Let's try putting the pieces of the codebase together into
a living breathing object, the same way a web browser brings a
web application alive. We'll start with a stagerunner but in
the future may end up with much more.</p>

<h2>The Execution Cycle</h2>

<div class="img-right">
  <img src="../../images/model_process.png" title="Model Process" />
</div>

<p>As mentioned earlier, a typical data science cycle begins with:
importing data, munging (cleaning) it, running a statistical classifier,
and exporting the model for validation and deployment.</p>

<p>A <b>stagerunner</b> is a single R object (specifically, an R6 object,
for those familiar with the R6 package which augments R's object-oriented
programming capabilities) that represents the full execution cycle
of the data science process. In workflows with large data sets, this
process is typically distributed across many machines in frameworks
like Spark and Hadoop. Since there is no distributed implementation
of the R interpreter (yet - shh ;) ) we focus for now on small and
medium size data problems. Typically, productionizing several 80%
solutions offers more business value than productionizing one 100% 
solution and anyway downsampling is often 
<a href="http://www.umiacs.umd.edu/~jimmylin/publications/Lin_Kolcz_SIGMOD2012.pdf">good enough</a>.</p>

<p>A stagerunner is simply a tree structure whose terminal nodes
are functions that operate on an <b>R environment object</b>. If you
are unfamiliar with R environments but understand pointers from
languages like C++, simply think of it as a pointer to a list. These
functions are executed linearly on the R environment starting with
the empty environment and culminating in side effects that export
a model, such as storing it to a backend like a cloud storage service or
a file. For the mathematically inclined, think of a stagerunner as
an element from finite sequences on the monoid of endomorphisms of R environments
with the additional meta-data of a hierarchical structure (a very
fancy way to say a list of functions that take and return
exactly one environment)</p>

<p>Some task scheduling frameworks like Luigi and Airflow take arbitrary
directed graphs of tasks and this is certainly the correct generalization
but can increase the difficulty of debugging failures in complex topologies
of tasks. Staying within a console tends to be much cozier.
Eventually Syberia may release this kind of hybrid in-console task 
scheduling and debugging but for now let's master stagerunners. (If you 
think hard enough about it, any directed graph can be decomposed into
purely serial components.)</p>

<h2>A simple stagerunner</h2>

<p>Before we jump into the convenient conventions set up by the modeling
engine that ships with Syberia by default, let's review the basics
of stagerunners.</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
r <- stagerunner$new(list2env(list(data = iris)), list(
  "Double first columns"     = function(env) { env$data[[1]] <- 2 * env$data[[1]] },
  "Drop categorical columns" = function(env) { env$data <- Filter(Negate(is.factor), env$data) }
))
r$run()
    </code>
  </pre>
</div>

<p>Ok so you got me, I lied a little. Stagerunner functions do not need to return the
environment they modify since this is one of the few R objects that is
passed by reference and not by value, and hence any modification in
another scope (like a function call) modifies the original environment object.</p>

<p>Observe that running the above code yields the desired changes:
<code class="inline">str(r$context$data)</code> shows we have a modified
version of <code class="inline">iris</code> with the first column doubled
and the only categorical column removed.</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
env <- list2env(list(data = iris))
r <- stagerunner$new(env, list(
  "Double first columns"     = function(env) { env$data[[1]] <- 2 * env$data[[1]] },
  "Drop categorical columns" = function(env) { env$data <- Filter(Negate(is.factor), env$data) }
))
r$run(1); r$run(1); r$run(1)
    </code>
  </pre>
</div>

<p>Inspecting <code class="inline">head(env$data[[1]])</code> shows that the first column of
<code class="inline">iris</code> is octupled as expected. Now try re-executing all but
the last line and type <code class="inline">r$run(2)</code>. The last column
was dropped, as expected.</p>

<p>This is an example of a <b>stateless stagerunner</b>: it has no memory about which
stages ("Double first columns" versus "Drop categorical columns") were executed.
Typically this matters as many feature engineering operations are not 
commutative: dropping correlated features and then imputing may yield
different results than doing it the other way around.</p>

<h2>More complicated runners</h2>

<div class="img-right">
  <img src="../../images/achievement-unlocked-template.jpg" title="Achievement unlocked" height="60" />
</div>

<p>To enforce the order of operation and gain an additional feature we
enable <b>stateful stagerunners</b>. This unlocks the ability to
<b>replay any part of the data science process</b> like checkpoints in a 
video game.

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
r <- stagerunner$new(list2env(list(data = iris)), list(
  "Double first columns"     = function(env) { env$data[[1]] <- 2 * env$data[[1]] },
  "Drop categorical columns" = function(env) { env$data <- Filter(Negate(is.factor), env$data) }
), remember = TRUE)
r$run(2)
    </code>
  </pre>
</div>

<p>Note the <code class="inline">remember = TRUE</code> flag at the end. The above
code will fail with "Cannot run this stage yet because some previous stages have not been executed."
This is because we are trying to run step two without first running step one. 
Running <code class="inline">r$run(1)</code> first will fix the problem.</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
env <- list2env(list(data = iris))
r <- stagerunner$new(env, list(
  "Double first columns"     = function(env) { env$data[[1]] <- 2 * env$data[[1]] },
  "Drop categorical columns" = function(env) { env$data <- Filter(Negate(is.factor), env$data) }
), remember = TRUE)
r$run(1); r$run(1); r$run(1)
    </code>
  </pre>
</div>

<p>Inspecting <code class="inline">head(env$data)</code> shows that the first column
of <code class="inline">iris</code> was doubled, not octupled! This is because 
with remembrance of state turned on our stagerunner object begins with
a cached copy of the original environment rather than operating on the 
latest environment. This is powerful: with stateful stagerunners, we can simulate
going back in time to any step in the process!</p>

<p>The code behind stagerunner makes some <a href="https://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff">space-time tradeoffs</a>. With stateful runners, <b>a full copy is made of 
the environment on each step</b>. This is prohibitively memory expensive
with large datasets. With small datasets, it is manageable and gives us 
fantastic interactive data analysis and debugging capabilities.</p>

<p>The typical workflow within the Syberia modeling engine is to 
use an R option or flag to import a small subset (a couple thousand rows)
of the desired data set and develop a full-fledged prototype of 
a feature engineering pipeline and classifier. Any immediate errors
or unexpected bugs in feature engineering can be rapidly debugged
by effectively using stagerunners.</p> 

<p>When the data scientist is satisfied with the end-to-end process,
she simply flips the stagerunner to run in a stateless context on the
full data set and gets to have her cake and eat it too; no more painful
debugging of background batch jobs or digging through logs.</p>

<p>A final goodie: by using <a href="https://github.com/robertzk/objectdiff">objectdiff</a>,
we can reduce the space-time tradeoff even further by <b>only copying the
elements of the environment that changed during each step</b>. If only
one column was doubled in a thousand-column dataframe, the stagerunner
and objectdiff combo heuristically analyzes the output of the functions
that are executed and rapidly detects only one column was changed, minimizing
how much is stored in the "git-like patches" recording the differences
in each stage. This retains the replay capability of stagerunners while
minimizing memory overhead.</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
env <- objectdiff::tracked_environment(list2env(list(data = iris)))
r <- stagerunner$new(env, list(
  "Double first columns"     = function(env) { env$data[[1]] <- 2 * env$data[[1]] },
  "Drop categorical columns" = function(env) { env$data <- Filter(Negate(is.factor), env$data) }
), remember = TRUE)
r$run()
    </code>
  </pre>
</div>

<p>Note that <code class="inline">class(env) == c("tracked_environment", "environment")</code>.
Inspecting <code class="inline">objectdiff::commits(env)</code> shows that two commits
have been made and running <code class="inline">objectdiff::rollback(env, 1)</code> shows
that <code class="inline">ncol(env$data) == 4</code>.

<code class="inline"></code>



        </div>
        <div class="col2">
          <br /> <br /> <br />
          SIDEBAR TEXT!
        </div>
      </div>
    </div>
  </div>
</body>
