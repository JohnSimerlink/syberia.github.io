<html>

  <head>
    <script src="https://use.typekit.net/xdj4hmw.js"></script>
    <script type="text/javascript">try { Typekit.load({ async: true }); } catch(e) { }</script>

    <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,500" rel="stylesheet" type="text/css">
    <link rel="stylesheet" media="all" href="../stylesheets/main.css" type="text/css" />
    <link rel="stylesheet" media="all" href="../stylesheets/rocco.css" />
    <link rel="stylesheet" media="all" href="../stylesheets/github-markdown.css" />

    <script src="../assets/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>
  </head>

  <body>
  <div class="backdrop tk-proxima-nova">
    <div class="header">
      <div class="header-left"><a href="/">Syberia</a></div>
      <div class="header-right">
        <ul>
          <li><a href="/docs">Get Started</a></li>
          <li><a href="/docs">Docs</a></li>
        </ul>
      </div>
    </div>
    <br /> <br /> <br />
  </div>
  <div class="colmask leftmenu tk-proxima-nova">
    <div class="colleft">
      <div class="col1">
<h1> Syberia Modeling 101 </h1>

<p>Ensure you understand the <a href="usage.html">basic usage</a> of the modeling engine
prior to proceeding.</p> 

<p>Developing classifiers using the Syberia modeling engine follows one
primary tenet: <b>development equals production</b>. When a
web developer experiments with a new website layout or feature, they
are targeting a <i>production system</i>. After they are satisfied
with their work, they push a button and deploy the code base so it
is live and others can interact with it.</p>

<p>Feature engineering and statistical modeling (as we will see,
inseparable components of machine learning) should belong to the
same class of work. When an architect designs a skyscraper their
work has to be translated to reality through a construction team 
by replaying the design using a physical medium. This is the current
industry standard for machine learning: prototype the model in
one language, typically a Python or R "notebook," and then 
write it in a "solid production-ready" language so it can survive
the harsh winds of the real world.</p>

<p><b>This is wrong</b>. Prior to the invention of HTML, construction of
UIs was a laborious design process that proceeded from the lab to the
factory. HTML, and later JavaScript, introduced a <i>syntax</i>, a <i>grammar</i>,
for rapidly experimenting with UIs and quickly pushing them to the
real world.</p>

<p>The tenet of using different languages for development and production
is fundamentally flawed. <i>Good syntax will always win</i> because it
records the critical mathematical abstractions relevant to the domain
and <a target="_new" href="http://asmjs.org/">retroactive optimization</a>
becomes possible.  Recoding your hardly fought experimental fruit
from R to Scala or from Python to C is a waste. Before HTML, inter-network
UIs were written in C and other lower languages. The world wide web
only exploded because it gave the power of rapid, iterative UI development
to <i>all</i> through a simple and straightforward syntax.</p>

<p>Teaching all the world's statisticians and applied mathematicians C, Java, or Scala 
to "productionize" their work is not a viable long-term strategy. The
only correct approach is to take the syntax, the mathematical notation,
most comfortable to these experts and then wielding a new world from it:
one that is alive.</p>

<p>Whether any aspect of the current Syberia framework
or its de facto modeling engine survives is irrelevant, in the same way
that VBScript ended up irrelevant, but it is important to <i>take that
  first step</i>. Do not be afraid to see real-time production-ready
hybrid stream-and-batch data processing and statistical prediction
as an <i>experimental</i> process that culminates in a finished product
the same way experimenting with a web app culminates in a deployable
real world tool <i>without additional code or re-implementation work</i>.</p>

<p>We have bothered with a philosophical prelude because we believe 
the statistician and scientist should come <i>first</i>: there
should be no "data engineer" trained in computer science and
difficult-to-master functional languages and distributed systems
to rewrite the work from scratch to make it "ready," at least to
the same extent there is no "web engineer" that takes a UI/UX expert's
JavaScript work and translates it to a C++ application every single time. All this
should be the corollary of a well-designed syntax, and the data engineering
task should be a one-time fully general abstract undertaking that implements
that syntax in the medium of streaming distributed systems. We are
trying to find that syntax, and R's
<a target="_new" href="https://en.wikipedia.org/wiki/Homoiconicity">homoiconicity</a>
and interactive nature forms the perfect testbed for finding that grail.</p> 

<p>Naturally, some organizations and performance-intensive applications
will continue to require full rewrites of the experimental designs, but
there is no reason why a well-designed syntax should not be capable of
auto-transpiling to the performance-optimized description, in the same
way that assembly languages were subsumed by higher abstract tools.</p>

<p>With all that said, let's jump into what a primordial first
iteration of a complete modeling grammar might look like. If you like
this approach to statistical modeling, maybe you can help us design
its future.</p>

<br />
<h2><a name="cycle">The Basic Modeling Cycle</a></h2>

<q>
The first analogy that came to my mind is of
immersing the nut in some softening liquid, and why not simply
water? From time to time you rub so the liquid penetrates better,
and otherwise you let time pass. The shell becomes more flexible
through weeks and months&mdash;when the time is ripe, hand pressure
is enough, the shell opens like a perfectly ripened avocado!
<br />
&mdash; <a target="_new" href="http://www.landsburg.com/grothendieck/mclarty1.pdf">Alexander Grothendieck</a>
</q>
<br />

<p>Finding well-designed syntax is <i>hard</i>. Historically, many achievements
in math and physics were a direct result thereof. Nevertheless, it is worth doing
because a successful execution allows you to think at a higher level of abstraction.
We start with the simplest possible grammar so that we may extend and build atop it
to achieve more complexity. We will do so without getting distracted by 
the latest and shiniest database tool or complex ensemble topology, but instead
with the meticulous patience of a mathematician, until the formerly daunting
seems trivial.</p>

<div class="img-right">
  <img src="../../images/model_process.png" title="Model Process" />
</div>
<p>For now, we stick with the standard supervised learning problem on
a binary or continuous predictor. Any instance of this machine learning
problem requires us to get data to perform analysis on.
On the other hand, typically "export" is
not embodied as a single button but as a process: re-coding the results
of the experimental sandbox analysis into a production codebase. The
Syberia approach is to turn this around and demand that all metadata
relevant to reproducing the modeling process in a real-time setting be
attached to a single serializable object. Fortunately, R makes this easy.</p>

<p>The first grammatic abstraction is a fairly commonplace one: that of
<b>I/O adapters</b>. We need a way to read in data, typically from a file
or a database, and a place to store our results, typically a file or 
cloud storage. We will see how defining short snippets of code in the
<code class="inline">lib/adapters</code> directory in a Syberia modeling
project allows us to import arbitrary data and export models arbitrarily.</p>

<p>What happens in the middle? Once we have the data, we typically have
to <i>clean it</i>. This is because the real world is messy and we rarely
get exactly what we expect: we may have missing values, mislabeled points,
insufficiently massaged features, and a whole host of other problems. Determining
which variables to keep after arduous experimentation can be 
first-order approximated using 
<a target="_new" href="https://cran.r-project.org/web/packages/SIS/index.html">sure independence screening</a>.
The process of data preparation in the Syberia modeling approach is
presently performed using <b>mungebits</b>, atomic production-ready 
feature engineering templates that allow us to quickly parametrize
the end-to-end cleaning process without having to write what usually
boils down to fairly repetitive code.
</p>
<p>The other, perhaps primary, purpose of mungebits is to encode any
metadata we may need to replay our feature engineering steps in production.
For example, if we imputed certain columns with the mean, we will have
to pre-record the means of each imputed column, as this information
will not be available in production when a new record streams in.
</p>

<p>After the data is "clean," in the sense that it forms a nearly complete
primarily numerical matrix without incorrectly labeled signals, we can try
a host of machine learning techniques on it: generalized linear models,
support vector machines, neural networks, clustering, random forests, and so on.
</p>

<p>
Typically, recording the model is done in a format like 
<a target="_new" href="https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language">PMML</a>,
but this is too restrictive. It forces us into a very limited set of
feature engineering steps and statistical parameters. Instead, we leverage
the power of R's LISP-like computation and store any code and data 
required to reproduce the predictions within a single R object called
a <b>tundra container</b> (named tundra because it freezes the model for 
production use :).
</p>

<p>To determine whether we are satisfied with the model, we have to apply
some sort of <i>validation</i>. Typically, this may be measuring the
<a target="_new" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">AUC</a>
of the predictions against a target threshold. Note that both feature engineering
and choice of statistical learning parameters may heavily influence performance.
</p>
<p>
Together with importing data and exporting results, the iterative process of
experimenting with feature engineering and statistical classifier parameters
forms the heart and intersection of most approaches to modeling problems,
so we will focus on solving this grammatical exercise until it becomes a trivial
feat before proceeding with higher grammars.
</p>
<p>Throughout, we aim to make the description of the modeling process as concise
as possible while retaining the tip of the iceberg composing the critical information. If
a model file ever grows to longer than 100 lines of code, it is a good sign
you should split it up and <b>refactor</b>. Let's revisit our earlier trivial example.</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
list(
  import = list(R = "iris"),
  data   = list(
    "Create dep var" = list(renamer, c("Sepal.Length" = "dep_var")),
    "Create ID var"  = list(multi_column_transformation(seq_along), "dep_var", "id")
  ),
  model  = list("lm", .id_var = "id"),
  export = list(R = "model")
)
    </code>
  </pre>
</div>

<p>The last expression of every model file is a list.
A list itself is a static object, but the assembly
of a list into a living, breathing avatar of the modeling process occurs 
internally when typing <code class="inline">run("example")</code>.</p>

<h2><a name="stages">The Four Stages</a></h2>

<p>
Let's break
down the four stages.</p>

<ol>
  <li><p><a target="_new" href="https://github.com/syberia/modeling.sy/blob/master/lib/stages/import.R">Importing data</a>
  is done through the import stage. This stage looks at 
  <code class="inline">lib/adapters</code> to find the necessary adapter.
  The modeling engine comes with several <a target="_new" href="https://github.com/syberia/modeling.sy/tree/master/lib/adapters">built-in adapters</a>,
  including the R, file, and S3 adapters for importing from and exporting to
  R's global environment, files, and Amazon's S3 cloud storage, respectively.
  Reading the name of the list element <code class="inline">"R"</code>
  from <code class="inline">list(R = "iris")</code> allows the import stage
  to pluck out <code class="inline">lib/adapters/R</code>.</p>
  <p>You can define a new way to import data by placing a file with
  <code class="inline">read</code> and/or <code class="inline">write</code> local
  variables holding functions in <code class="inline">lib/adapters/your_new_adapter.R</code>
  and then replacing the first stage with
  <code class="inline">import = list(your_new_adapter = ...)</code> where the
  right-hand side is the parametrization that will be passed to the
  <code class="inline">read</code> function. Later, we will examine further
  how to do this (and test that it works as expected).
  </p>
  </li>
  <li><p><a target="_new" href="https://github.com/syberia/modeling.sy/blob/master/lib/stages/data.R">Munging</a>
  the data is achieved through the data stage. Each stage accepts
  its own parametrization and convention. While the import stage is 
  relatively simple, describing merely the external location of the data,
  the data stage can be as complicated as you need it to be.</p>
  <p>The vanilla data stage is parametrized by a named list, with each
  list element name representing a very brief summary of the feature engineering
  or cleaning step, and the list element value representing a grammar of
  data preparation we will explain down the road.</p>
  <p> The nice thing about this 
  grammar is that it allows us to write almost any operation on the data
  set in one line of code and separate the abstract parametrized code
  for performing the operation into a separate place, <code class="inline">lib/mungebits</code>,
  where all of its inputs and outputs can be thoroughly tested and
  ensured of correctness.</p>
  </li>
  <li><p>Running the <a target="_new" href="https://github.com/syberia/modeling.sy/blob/master/lib/stages/model.R">model</a>!
  This step is frequently and incorrectly viewed as the most important component
  of the modeling process: the secret sauce is in finding the correct parameters
  to a magical mathematical method. <b>This is wrong</b>. Once you start writing
  some Syberia modeling files, you will see that the meat often lies primarily
  in the data preparation, not in the statistical method. It is a pity that most books
  on machine learning do not make this acknowledgement.
  </p>
  <p>
  The parametrization for the model stage is simple: a list whose first element describes
  the name of the classifier we will use, which convention dictates it fetches
  from <code class="inline">lib/classifiers/lm.R</code>. Any file in
  that directory will be a short R file containing two local variables,
  <code class="inline">train</code> and <code class="inline">predict</code>,
  where the former records the metadata required to play the predictions
  on any subsample of the original dataset (in particular, single rows of
  streaming data). Typically, this is what we refer to when we say we are
  estimating the "parameters" of a statistical learning function.
  </p>
  <p>The rest of the list elements will be fed directly to the <code class="inline">train</code>
  function after the data has been cleaned. The Syberia modeling engine
  provides the shortcut <code class="inline">M</code> to represent the model
  object so that we can preview some predictions using 
  <code class="inline">M$predict(validation_data)</code>.</p>
  <p>Hand-in-hand with some function <code class="inline">validate(M)</code>, 
  we can downsample the import stage prior to experimentation and
  use the re-running functionality to play <code class="inline">run(, 3)</code>
  (i.e., re-run the model stage) to make a succession of plots or estimates
  of the efficacy of various parameters, before settling on a choice for the
  final dataset. This is a typical approach to experimenting with data sets that
  fit into memory, but there is a way to make it work on arbitrarily large data sets as well.
  </p>
  </li>
  <li><p><a target="_new" href="https://github.com/syberia/modeling.sy/blob/master/lib/stages/export.R">Exporting</a>
  the model. Borrowing from the adapters introduced in the import stage,
  this stage follows a similar parametrization: the name of each list
  element should correspond to an entry in <code class="inline">lib/adapters</code>
  with a <code class="inline">write</code> local variable determining
  how to save the model object based off the parametrizations provided
  on the right-hand side.</p>
  <p>In our trivial example, we exported to the R global environment so we can inspect
  our model. If we are happy, we could add <code class="inline">file = "~/tmp/model.RDS"</code>
  (or even better, use an S3 key) indicating we are using the <code class="inline">file</code>
  adapter to export the model object for later use.
  Typing <code class="inline">run(, 4)</code> will re-run the export stage with
  this new export adapter, recording our model permanently.
  </p>
  </li>
</ol>

<p>The example we described is a trivial one. What if we wanted to do
something more complicated? Imagine we would like to import data from a database,
run three complex feature engineering steps (say principal component analysis,
some time series aggregation, and sure independence screening), followed by
running a model with a new package we found on CRAN, and then exporting
the serialized object to a Mongo database.</p>
<p>How much work would we have to do?</p>

<div class="code">
  <pre>
    <code class="R"><span class="spacer">
# models/dev/fancy_model.R
list(
  import = list(database = list(table = "my_data")),
  data   = list(
    "Aggregate time series" = list(aggregate_ts, vars = c("timevar1", "timevar2")),
    "Sure indep screening"  = list(sis, pval_threshold = 0.05),
    "Principal components"  = list(pca, center = TRUE, scale = TRUE)
  ),
  model  = list("fancy_model", param1 = 0.7, param2 = "foo")
  export = list(mongo = "models/experimental/fancy_model/1")
)
    </span></code>
  </pre>
</div>

<ol>
  <li>We would have to write a <code class="inline">database.R</code>
  and <code class="inline">mongo.R</code> file with a <code class="inline">read</code>
  and <code class="inline">write</code> method, respectively,
  placing them in <code class="inline">lib/adapters</code>.
  (And write tests! More on this later.)
  </li>
  <li>We would need <code class="inline">sis.R</code>, <code class="inline">aggregate_ts.R</code>,
  and <code class="inline">pca.R</code> in <code class="inline">lib/mungebits</code>. We will
  examine later what goes into writing mungebits, but it isn't much.</li>
  <li>We would need to wrap the CRAN package in a
  <code class="inline">lib/classifiers/fancy_model.R</code> file.</li>
</ul>

<p> In total, we had to touch <b>six files</b>, excluding the model file, with
some huge benefits: (1) as we will see later, each of our files requires
tests for the project to pass continuous integration, ensuring we are
confident the results are correct, and (2) we have made the fruits of our
work accessible to anyone else working on the project!</p>

<p>This latter point is crucial:
if we had written a linear, serial script, someone would later have to go
dig through our model, potentially sprawled across several files,
to figure out what to copy and where to inject new parameters to
appropriate to their particular data set. If six months later we have written
100 models that used <code class="inline">pca</code> and discovered
a subtle bug, we could fix all models simultaneously instead of wading
through old files or notebooks that will inevitably be forgotten.</p>
<p>Forget notebooks. By thinking like developers even when experimenting,
we can grow stronger. We can have the best of both worlds.
By writing the modeling process in this way, the Syberia modeling engine
is forcing the work we write to be <b>modular</b>, <b>testable</b>, and <b>reproducible</b>,
preferably in a <a target="_new" href="https://en.wikipedia.org/wiki/Version_control">versioned</a>
codebase that records all of history.</p>

<p>This is what gave great power to frameworks like 
<a target="_new" href="https://en.wikipedia.org/wiki/Ruby_on_Rails">Ruby on Rails</a>,
tools that were not hailed theoretical results yet empowered formerly 
siloed developers to harness the benefits of
<a target="_new" href="https://en.wikipedia.org/wiki/Convention_over_configuration">convention over configuration</a>
and reach developer productivity and project iteration speeds that
were formerly inaccessible.</p>
 
<p>The dream of the modeling engine is to reach and surpass this level
of productivity as applied to the domain of, well,
<a target="_new" href="https://cran.r-project.org/web/views/">whatever it is that R does</a>!
Machine learning is only the beginning.</p>

<h1>Next Steps</h1>

<ul>
  <li><a href="mungebits.html">Mungebits</a></li>
  <li><a href="stagerunner.html">Stagerunner</a></li>
  <li><a href="tundra.html">Model objects</a></li>
  <li><a href="director.html">Controllers</a></li>
</ul>

        </div>
        <div class="col2">
          <br /> <br /> <br />
        <ul class="table-of-contents">
          <li>
            <a href="/docs">Introduction</a></li>
            <ul>
              <li><a href="/docs#example">An example</a></li>
              <li><a href="/docs#additional_resources">Additional resources</a></li>
            </ul>
          <li><a href="/docs/download.html">Download and Setup</a>
            <ul>
              <li><a href="/docs/download.html#trouble">Troubleshooting</a></li>
            </ul>
          </li>
          <li><a href="/docs/usage.html">Basic Usage</a></li>
          <li><a href="/docs/101.html">Modeling 101</a>
            <ul>
              <li><a href="/docs/101.html#cycle">The Basic Modeling Cycle</a></li>
              <li><a href="/docs/101.html#stages">The Four Stages</a></li>
            </ul>
          </li>
          <li><a href="/docs/mungebits.html">Mungebits <img src="/images/octocat.png" width="32" /></a>
            <ul>
              <li><a href="/docs/mungebits.html#basic">The Basic Mungebit</a></li>
              <li><a href="/docs/mungebits.html#testing">Testing Mungebits</a></li>
              <li><a href="/docs/mungebits.html#advanced">Advanced Mungebits</a></li>
            </ul>
          </li>
          <li><a href="/docs/stagerunner.html">Stagerunner</a>
            <ul>
              <li><a href="/docs/stagerunner.html#cycle">The Execution Cycle</a></li>
              <li><a href="/docs/stagerunner.html#simple">A Simple Stagerunner</a></li>
              <li><a href="/docs/stagerunner.html#complicated">More Complicated Runners</a></li>
              <li><a href="/docs/stagerunner.html#engine">The Modeling Engine</a></li>
              <li><a href="/docs/stagerunner.html#rerun">Re-running Stages</a></li>
              <li><a href="/docs/stagerunner.html#modeling">The Modeling Cycle</a></li>
            </ul>
          </li>
          <li><a href="/docs/tundra.html">Model Objects</a>
            <ul>
              <li><a href="/docs/tundra.html#container">The Tundra Container</a></li>
              <li><a href="/docs/tundra.html#serialization">Serialization of Model Objects</a></li>
              <li><a href="/docs/tundra.html#construction">Constructing Model Objects</li>
              <li><a href="/docs/tundra.html#engine">Help From The Modeling Engine</a></li>
              <li><a href="/docs/tundra.html#deflation">Appendix: Model Deflation</a></li>
              <li><a href="/docs/tundra.html#serializing">Appendix: Custom Serializers</a></li>
            </ul>
          </li>
          <li><a href="/docs/director.html">Managing Large Projects</a>
            <ul>
              <li><a href="/docs/director.html#conventions">Modeling Engine Conventions</a></li>
              <li><a href="/docs/director.html#base">The Base Engine</a></li>
              <li><a href="/docs/director.html#basic">Basic Director Object</a></li>
              <li><a href="/docs/director.html#preprocessor">Preprocessors and Parsers</a></li>
              <li><a href="/docs/director.html#additional">Additional Functionality</a></li>
            </ul>
          </li>
          <li><a href="/docs/testing.html">Testing</a>
            <ul>
              <li><a href="/docs/testing.html#defining">Defining Tests</a></li>
              <li><a href="/docs/testing.html#models">Testing Models</a></li>
              <li><a href="/docs/testing.html#configuration">Test Configuration</a></li>
              <li><a href="/docs/testing.html#ci">Continuous Integration</a></li>
            </ul>
          </li>
          <li><a href="/docs/summary.html">Summary and Review</a>
            <ul>
              <li><a href="/docs/summary.html#modeling">The Modeling Engine</a></li>
              <li><a href="/docs/summary.html#base">The Base Engine</a></li>
              <li><a href="/docs/summary.html#grammar">The Modeling Grammar</a></li>
              <li><a href="/docs/summary.html#mungebits">Mungebits</a></li>
            </ul>
          </li>
        </ul>
        </div>
      </div>
    </div>
  </div>
</body>
